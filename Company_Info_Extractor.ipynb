{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "9b799982",
      "metadata": {
        "id": "9b799982"
      },
      "source": [
        "# LSPP Assignment - Intelligent Agent: Information Extraction\n",
        "\n",
        "This notebook extracts structured company information from essays using LangChain's LCEL (LangChain Expression Language) and Google's Gemini API. It processes text paragraph-by-paragraph to extract:\n",
        "\n",
        "- **Company Name**: The name of the company\n",
        "- **Founding Date**: When the company was founded (normalized to YYYY-MM-DD format)\n",
        "- **Founders**: List of founders (real human names only)\n",
        "\n",
        "## Features\n",
        "\n",
        "- 📝 Paragraph-wise extraction using LCEL\n",
        "- 📅 Smart date normalization (handles various formats like \"2010\", \"March 2010\", \"March 15, 2010\")\n",
        "- 📊 CSV output with proper formatting\n",
        "- 🔄 Rate limiting to avoid API quota issues\n",
        "- 🔍 Preview functionality to see results before saving\n",
        "\n",
        "## Setup Requirements\n",
        "\n",
        "- Google Colab environment\n",
        "- Gemini API key (stored in Colab secrets)\n",
        "- Internet connection for package installation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "D0IxXdq1VRF4",
      "metadata": {
        "id": "D0IxXdq1VRF4"
      },
      "source": [
        "# 🎯 How to Use This Notebook\n",
        "\n",
        "### Step 1: Setup\n",
        "1. **Add your Gemini API key** to Google Colab secrets:\n",
        "   - Click the 🔑 icon in the left sidebar\n",
        "   - Add a new secret named `GEMINI_API_KEY`\n",
        "   - Paste your API key as the value\n",
        "\n",
        "### Step 2: Run the Cells\n",
        "1. **Run all cells** from top to bottom (Runtime → Run all)\n",
        "2. The notebook will automatically process the sample essay text\n",
        "3. Results will be displayed and saved to `company_info.csv`\n",
        "\n",
        "### Step 3: Customize (Optional)\n",
        "\n",
        "#### Use Your Own Text\n",
        "Replace the `SAMPLE_ESSAY` variable with your own text:\n",
        "\n",
        "```python\n",
        "# Replace SAMPLE_ESSAY with your text\n",
        "SAMPLE_ESSAY = \"\"\"Your essay text here...\"\"\"\n",
        "```\n",
        "\n",
        "#### Upload a Text File\n",
        "```python\n",
        "# Upload and read a text file\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "filename = list(uploaded.keys())[0]\n",
        "with open(filename, 'r', encoding='utf-8') as f:\n",
        "    SAMPLE_ESSAY = f.read()\n",
        "```\n",
        "\n",
        "#### Adjust Configuration\n",
        "Modify the `CONFIG` dictionary to customize behavior:\n",
        "\n",
        "```python\n",
        "CONFIG = {\n",
        "    'delay_sec': 2.0,          # Increase for stricter rate limiting\n",
        "    'max_paragraphs': 5,       # Limit for testing (None = all)\n",
        "    'show_preview': True,      # Show results preview\n",
        "    'output_csv': 'my_companies.csv'  # Custom output filename\n",
        "}\n",
        "```\n",
        "\n",
        "### Output Format\n",
        "\n",
        "The CSV file contains these columns:\n",
        "- **S.N.**: Serial number\n",
        "- **Company Name**: Extracted company name\n",
        "- **Founded in**: Founding date (YYYY-MM-DD format)\n",
        "- **Founded by**: List of founders (JSON format)\n",
        "\n",
        "### Troubleshooting\n",
        "\n",
        "- **API Key Error**: Make sure your `GEMINI_API_KEY` is correctly set in Colab secrets\n",
        "- **Rate Limit Error**: Increase `delay_sec` in the configuration\n",
        "- **No Results**: Check if your text contains clear company founding information\n",
        "- **Date Format Issues**: The system handles various date formats automatically\n",
        "\n",
        "### Download Results\n",
        "\n",
        "```python\n",
        "# Download the CSV file\n",
        "from google.colab import files\n",
        "files.download('company_info.csv')\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "87a0bd61",
      "metadata": {
        "id": "87a0bd61"
      },
      "source": [
        "## 1. Install Required Dependencies\n",
        "\n",
        "First, we'll install all the necessary packages for our company information extraction project."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87d7f4d6",
      "metadata": {
        "id": "87d7f4d6"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install langchain-google-genai pydantic python-dotenv python-dateutil langchain-core langchain -qU"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e957e299",
      "metadata": {
        "id": "e957e299"
      },
      "source": [
        "## 2. Import Libraries and Setup\n",
        "\n",
        "Import all required libraries and configure Google Colab secrets to access the Gemini API key."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c77a9f50",
      "metadata": {
        "id": "c77a9f50"
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "import os\n",
        "import re\n",
        "import csv\n",
        "import json\n",
        "import time\n",
        "from datetime import date\n",
        "from typing import List, Union\n",
        "from pathlib import Path\n",
        "\n",
        "# Pydantic imports\n",
        "from pydantic import BaseModel, Field, field_validator\n",
        "\n",
        "# LangChain imports\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "# Date parsing\n",
        "from dateutil import parser as date_parser\n",
        "\n",
        "# Google Colab secrets\n",
        "from google.colab import userdata\n",
        "\n",
        "# Setup API key from Google Colab secrets\n",
        "# Make sure to add your GEMINI_API_KEY in Colab secrets (🔑 icon in the sidebar)\n",
        "try:\n",
        "    api_key = userdata.get('GEMINI_API_KEY')\n",
        "    os.environ['GOOGLE_API_KEY'] = api_key\n",
        "    print(\"✅ API key loaded successfully from Colab secrets\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Error loading API key: {e}\")\n",
        "    print(\"Please add your GEMINI_API_KEY to Colab secrets (🔑 icon in sidebar)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee107ea0",
      "metadata": {
        "id": "ee107ea0"
      },
      "source": [
        "## 3. Define Pydantic Schemas with Date Normalization\n",
        "\n",
        "Create data models for company information with smart date parsing that handles various date formats."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b9cf93d",
      "metadata": {
        "id": "0b9cf93d"
      },
      "outputs": [],
      "source": [
        "# Month mapping for date parsing\n",
        "MONTHS = {m.lower(): i for i, m in enumerate([\n",
        "    \"\", \"January\",\"February\",\"March\",\"April\",\"May\",\"June\",\"July\",\"August\",\"September\",\"October\",\"November\",\"December\"\n",
        "])}\n",
        "\n",
        "def normalize_partial_date(text: str) -> date:\n",
        "    \"\"\"\n",
        "    Normalize various date formats to a standard date object.\n",
        "    Handles formats like:\n",
        "    - YYYY (e.g., \"2010\") → 2010-01-01\n",
        "    - Month YYYY (e.g., \"March 2010\") → 2010-03-01\n",
        "    - YYYY-MM-DD (e.g., \"2010-03-15\") → 2010-03-15\n",
        "    - Month D, YYYY (e.g., \"March 15, 2010\") → 2010-03-15\n",
        "    \"\"\"\n",
        "    s = text.strip()\n",
        "\n",
        "    # Handle full date format YYYY-MM-DD\n",
        "    m_full = re.fullmatch(r\"(\\d{4})-(\\d{2})-(\\d{2})\", s)\n",
        "    if m_full:\n",
        "        y, mo, d = map(int, m_full.groups())\n",
        "        return date(y, mo, d)\n",
        "\n",
        "    # Try parsing with dateutil for complex formats\n",
        "    try:\n",
        "        dt = date_parser.parse(s, default=date(1900, 1, 1), dayfirst=False, fuzzy=True)\n",
        "\n",
        "        # Handle year-only format (e.g., \"2010\")\n",
        "        year_match = re.fullmatch(r\"\\d{4}\", s)\n",
        "        if year_match:\n",
        "            return date(int(year_match.group(0)), 1, 1)\n",
        "\n",
        "        # Handle Month YYYY format (e.g., \"March 2010\")\n",
        "        month_year = re.fullmatch(r\"([A-Za-z]+)\\s+(\\d{4})\", s)\n",
        "        if month_year:\n",
        "            mo = MONTHS.get(month_year.group(1).lower(), 1)\n",
        "            return date(int(month_year.group(2)), mo, 1)\n",
        "\n",
        "        # Use parsed date\n",
        "        return date(dt.year, dt.month, dt.day)\n",
        "    except Exception:\n",
        "        # Fallback: extract year and try to find month\n",
        "        m_year = re.search(r\"(\\d{4})\", s)\n",
        "        if m_year:\n",
        "            y = int(m_year.group(1))\n",
        "            # Try to find month name\n",
        "            m_name = re.search(r\"(January|February|March|April|May|June|July|August|September|October|November|December)\", s, re.IGNORECASE)\n",
        "            if m_name:\n",
        "                mo = MONTHS[m_name.group(1).lower()]\n",
        "                return date(y, mo, 1)\n",
        "            return date(y, 1, 1)\n",
        "        raise ValueError(f\"Unrecognized date format: {text}\")\n",
        "\n",
        "class CompanyInfo(BaseModel):\n",
        "    \"\"\"Model for individual company information.\"\"\"\n",
        "    company_name: str\n",
        "    founding_date: date\n",
        "    founders: List[str]\n",
        "\n",
        "    @field_validator(\"founding_date\", mode=\"before\")\n",
        "    @classmethod\n",
        "    def _parse_date(cls, v: Union[str, date]):\n",
        "        if isinstance(v, date):\n",
        "            return v\n",
        "        return normalize_partial_date(str(v))\n",
        "\n",
        "class ParagraphExtraction(BaseModel):\n",
        "    \"\"\"Model for extraction results from a single paragraph.\"\"\"\n",
        "    items: List[CompanyInfo]\n",
        "\n",
        "# Test the date normalization function\n",
        "test_dates = [\"2010\", \"March 2010\", \"2010-03-15\", \"March 15, 2010\", \"April 4, 1975\"]\n",
        "print(\"📅 Date Normalization Examples:\")\n",
        "for test_date in test_dates:\n",
        "    try:\n",
        "        normalized = normalize_partial_date(test_date)\n",
        "        print(f\"  '{test_date}' → {normalized.isoformat()}\")\n",
        "    except Exception as e:\n",
        "        print(f\"  '{test_date}' → Error: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6429b97b",
      "metadata": {
        "id": "6429b97b"
      },
      "source": [
        "## 4. Build LLM and Text Processing Functions\n",
        "\n",
        "Set up the Gemini LLM instance and create functions to process text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a089be4e",
      "metadata": {
        "id": "a089be4e"
      },
      "outputs": [],
      "source": [
        "def build_llm(model_name: str = None, temperature: float = 0.0):\n",
        "    \"\"\"Build and configure the Gemini LLM instance.\"\"\"\n",
        "    api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
        "    if not api_key:\n",
        "        raise RuntimeError(\"GOOGLE_API_KEY is not set. Please check your Colab secrets.\")\n",
        "\n",
        "    api_key = api_key.strip()\n",
        "    model = model_name or \"gemini-1.5-flash\"  # Use flash model for lower quota usage\n",
        "\n",
        "    return ChatGoogleGenerativeAI(\n",
        "        model=model,\n",
        "        temperature=temperature,\n",
        "        api_key=api_key\n",
        "    )\n",
        "\n",
        "def split_into_paragraphs(text: str) -> List[str]:\n",
        "    \"\"\"Split text into individual paragraphs for processing.\"\"\"\n",
        "    paras = [p.strip() for p in re.split(r\"\\n\\s*\\n\", text) if p.strip()]\n",
        "    return paras\n",
        "\n",
        "# Test the functions\n",
        "print(\"🤖 Testing LLM connection...\")\n",
        "try:\n",
        "    llm = build_llm()\n",
        "    print(\"✅ LLM connection successful!\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ LLM connection failed: {e}\")\n",
        "\n",
        "# Test paragraph splitting\n",
        "sample_text = \"\"\"This is paragraph one.\n",
        "It has multiple lines.\n",
        "\n",
        "This is paragraph two.\n",
        "With different content.\n",
        "\n",
        "And this is paragraph three.\"\"\"\n",
        "\n",
        "paragraphs = split_into_paragraphs(sample_text)\n",
        "print(f\"\\n📝 Paragraph splitting test:\")\n",
        "print(f\"  Input: {len(sample_text)} characters\")\n",
        "print(f\"  Output: {len(paragraphs)} paragraphs\")\n",
        "for i, para in enumerate(paragraphs, 1):\n",
        "    print(f\"    {i}. {para[:50]}{'...' if len(para) > 50 else ''}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "646415a6",
      "metadata": {
        "id": "646415a6"
      },
      "source": [
        "## 5. Create Extraction Chain and Processing Logic\n",
        "\n",
        "Build the LCEL chain for extracting company information and implement the main processing logic."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f15f0712",
      "metadata": {
        "id": "f15f0712"
      },
      "outputs": [],
      "source": [
        "def _build_one_paragraph_chain():\n",
        "    \"\"\"Build the LCEL chain for processing a single paragraph.\"\"\"\n",
        "    llm = build_llm()\n",
        "\n",
        "    # Create the prompt template\n",
        "    prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"system\",\n",
        "         \"Extract company founding facts from the paragraph. \"\n",
        "         \"Return items as a JSON object matching the schema 'ParagraphExtraction'. \"\n",
        "         \"Each item must include: company_name (string), founding_date (string, can be YYYY, YYYY-MM or YYYY-MM-DD), \"\n",
        "         \"and founders (list of strings; only real human names). \"\n",
        "         \"If multiple companies are present, include them all. \"\n",
        "         \"If no companies are found, return an empty list.\"),\n",
        "        (\"human\", \"{paragraph}\")\n",
        "    ])\n",
        "\n",
        "    # Create structured output chain\n",
        "    structured = llm.with_structured_output(ParagraphExtraction)\n",
        "\n",
        "    # Return the complete chain\n",
        "    return prompt | structured\n",
        "\n",
        "def run_extraction(text: str, delay_sec: float = 1.0, max_paragraphs: int = None) -> List[CompanyInfo]:\n",
        "    \"\"\"\n",
        "    Sequentially process each paragraph to avoid rate limits and return extracted companies.\n",
        "\n",
        "    Args:\n",
        "        text: Input text to process\n",
        "        delay_sec: Delay between API calls to avoid rate limits\n",
        "        max_paragraphs: Maximum number of paragraphs to process (for testing)\n",
        "\n",
        "    Returns:\n",
        "        List of extracted CompanyInfo objects\n",
        "    \"\"\"\n",
        "    print(\"🔄 Starting extraction process...\")\n",
        "\n",
        "    # Split text into paragraphs\n",
        "    paragraphs = split_into_paragraphs(text)\n",
        "    if max_paragraphs:\n",
        "        paragraphs = paragraphs[:max_paragraphs]\n",
        "        print(f\"📝 Limited to first {max_paragraphs} paragraphs\")\n",
        "\n",
        "    print(f\"📄 Processing {len(paragraphs)} paragraphs...\")\n",
        "\n",
        "    # Build the extraction chain\n",
        "    extraction_chain = _build_one_paragraph_chain()\n",
        "\n",
        "    # Process each paragraph\n",
        "    all_items: List[CompanyInfo] = []\n",
        "    results: List[ParagraphExtraction] = []\n",
        "\n",
        "    for i, paragraph in enumerate(paragraphs, 1):\n",
        "        print(f\"  Processing paragraph {i}/{len(paragraphs)}...\")\n",
        "        try:\n",
        "            # Extract companies from this paragraph\n",
        "            result: ParagraphExtraction = extraction_chain.invoke({\"paragraph\": paragraph})\n",
        "            results.append(result)\n",
        "\n",
        "            # Add extracted companies to our list\n",
        "            if result.items:\n",
        "                all_items.extend(result.items)\n",
        "                print(f\"    ✅ Found {len(result.items)} companies\")\n",
        "            else:\n",
        "                print(f\"    ℹ️ No companies found\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"    ❌ Error processing paragraph {i}: {e}\")\n",
        "\n",
        "        # Rate limiting delay\n",
        "        if delay_sec and i < len(paragraphs):\n",
        "            print(f\"    ⏳ Waiting {delay_sec}s to avoid rate limits...\")\n",
        "            time.sleep(delay_sec)\n",
        "\n",
        "    print(f\"✅ Extraction complete! Found {len(all_items)} total companies.\")\n",
        "    return all_items\n",
        "\n",
        "# Test with a small sample\n",
        "test_text = \"\"\"\n",
        "Microsoft Corporation was founded in 1975 by Bill Gates and Paul Allen. The company started as a small software company.\n",
        "\n",
        "Apple Inc. was founded on April 1, 1976 by Steve Jobs, Steve Wozniak, and Ronald Wayne. The company revolutionized personal computing.\n",
        "\n",
        "Google was founded in September 1998 by Larry Page and Sergey Brin while they were PhD students at Stanford University.\n",
        "\"\"\"\n",
        "\n",
        "print(\"🧪 Testing extraction with sample text...\")\n",
        "try:\n",
        "    test_results = run_extraction(test_text, delay_sec=0.5, max_paragraphs=2)\n",
        "    print(f\"\\n📊 Test Results:\")\n",
        "    for i, company in enumerate(test_results, 1):\n",
        "        print(f\"  {i}. {company.company_name}\")\n",
        "        print(f\"     Founded: {company.founding_date.isoformat()}\")\n",
        "        print(f\"     Founders: {', '.join(company.founders)}\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Test failed: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5194845",
      "metadata": {
        "id": "b5194845"
      },
      "source": [
        "## 6. Define CSV Writing Functions\n",
        "\n",
        "Create functions to write extracted company data to CSV format with proper formatting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d36e9f9",
      "metadata": {
        "id": "3d36e9f9"
      },
      "outputs": [],
      "source": [
        "def append_csv(csv_path: str, company_name: str, founding_date: str, founders: List[str]) -> str:\n",
        "    \"\"\"\n",
        "    Append a company entry to CSV file with proper serial numbering.\n",
        "\n",
        "    Args:\n",
        "        csv_path: Path to the CSV file\n",
        "        company_name: Name of the company\n",
        "        founding_date: Founding date in YYYY-MM-DD format\n",
        "        founders: List of founder names\n",
        "\n",
        "    Returns:\n",
        "        Status message\n",
        "    \"\"\"\n",
        "    path = Path(csv_path)\n",
        "    new_file = not path.exists()\n",
        "\n",
        "    # Create directory if it doesn't exist\n",
        "    path.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Calculate serial number\n",
        "    sn = 1\n",
        "    if not new_file:\n",
        "        try:\n",
        "            with path.open(\"r\", encoding=\"utf-8\") as r:\n",
        "                rows = list(csv.reader(r))\n",
        "            sn = len(rows)  # header is row 1, so this gives us the next S.N.\n",
        "        except Exception:\n",
        "            sn = 1\n",
        "\n",
        "    # Write to CSV\n",
        "    with path.open(\"a\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "        writer = csv.writer(f)\n",
        "\n",
        "        # Write header for new file\n",
        "        if new_file:\n",
        "            writer.writerow([\"S.N.\", \"Company Name\", \"Founded in\", \"Founded by\"])\n",
        "\n",
        "        # Convert founders list to JSON string for CSV storage\n",
        "        founders_str = json.dumps(founders, ensure_ascii=False)\n",
        "\n",
        "        # Write the data row\n",
        "        writer.writerow([sn, company_name, founding_date, founders_str])\n",
        "\n",
        "    return f\"Appended {company_name} to {csv_path}\"\n",
        "\n",
        "def write_csv(items: List[CompanyInfo], out_csv: str) -> str:\n",
        "    \"\"\"\n",
        "    Write all extracted companies to a CSV file.\n",
        "\n",
        "    Args:\n",
        "        items: List of CompanyInfo objects\n",
        "        out_csv: Output CSV file path\n",
        "\n",
        "    Returns:\n",
        "        Status message\n",
        "    \"\"\"\n",
        "    path = Path(out_csv)\n",
        "\n",
        "    # Remove existing file to start fresh\n",
        "    if path.exists():\n",
        "        path.unlink()\n",
        "\n",
        "    # Write each company using append_csv to ensure proper formatting\n",
        "    for item in items:\n",
        "        append_csv(\n",
        "            csv_path=out_csv,\n",
        "            company_name=item.company_name,\n",
        "            founding_date=item.founding_date.isoformat(),\n",
        "            founders=item.founders,\n",
        "        )\n",
        "\n",
        "    return f\"Successfully wrote {len(items)} companies to {out_csv}\"\n",
        "\n",
        "def preview_results(items: List[CompanyInfo], max_items: int = 10):\n",
        "    \"\"\"Display a preview of extracted companies.\"\"\"\n",
        "    print(f\"📊 Preview of extracted companies (showing {min(len(items), max_items)} of {len(items)}):\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "    for i, item in enumerate(items[:max_items], 1):\n",
        "        print(f\"{i:2d}. Company: {item.company_name}\")\n",
        "        print(f\"     Founded: {item.founding_date.isoformat()}\")\n",
        "        print(f\"     Founders: {', '.join(item.founders)}\")\n",
        "        print()\n",
        "\n",
        "    if len(items) > max_items:\n",
        "        print(f\"... and {len(items) - max_items} more companies\")\n",
        "\n",
        "# Test CSV functions with sample data\n",
        "print(\"🧪 Testing CSV functions...\")\n",
        "sample_companies = [\n",
        "    CompanyInfo(company_name=\"Test Corp\", founding_date=\"2020-01-01\", founders=[\"John Doe\", \"Jane Smith\"]),\n",
        "    CompanyInfo(company_name=\"Example Inc\", founding_date=\"2021-06-15\", founders=[\"Bob Johnson\"])\n",
        "]\n",
        "\n",
        "test_csv_path = \"test_companies.csv\"\n",
        "try:\n",
        "    result = write_csv(sample_companies, test_csv_path)\n",
        "    print(f\"✅ {result}\")\n",
        "\n",
        "    # Read and display the CSV content\n",
        "    with open(test_csv_path, 'r', encoding='utf-8') as f:\n",
        "        content = f.read()\n",
        "    print(f\"\\n📄 CSV Content:\")\n",
        "    print(content)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"❌ CSV test failed: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40cf5bf2",
      "metadata": {
        "id": "40cf5bf2"
      },
      "source": [
        "## 7. Main Execution and Results Display\n",
        "\n",
        "Now let's put everything together and run the complete extraction pipeline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a97ccc1b",
      "metadata": {
        "id": "a97ccc1b"
      },
      "outputs": [],
      "source": [
        "# Sample essay text for demonstration\n",
        "\n",
        "SAMPLE_ESSAY = \"\"\"\n",
        "In the ever-evolving landscape of global commerce, the origin stories of major corporations are not merely tales of personal ambition and entrepreneurial spirit but also reflections of broader socio-economic trends and technological revolutions that have reshaped industries. These narratives, which often begin with modest ambitions, unfold into chronicles of innovation and strategic foresight that define industries and set benchmarks for future enterprises.\n",
        "Early Foundations: Pioneers of Industry\n",
        "One of the earliest examples is The Coca-Cola Company, founded on May 8, 1886, by Dr. John Stith Pemberton in Atlanta, Georgia. Initially sold at Jacob's Pharmacy as a medicinal beverage, Coca-Cola would become one of the most recognized brands worldwide, revolutionizing the beverage industry.\n",
        "Similarly, Sony Corporation was established on May 7, 1946, by Masaru Ibuka and Akio Morita in Tokyo, Japan. Starting with repairing and building electrical equipment in post-war Japan, Sony would grow to pioneer electronics, entertainment, and technology.\n",
        "As the mid-20th century progressed, McDonald's Corporation emerged as a game-changer in the fast-food industry. Founded on April 15, 1955, in Des Plaines, Illinois, by Ray Kroc, McDonald's built upon the original concept of Richard and Maurice McDonald to standardize and scale fast-food service globally. Around the same period, Intel Corporation was established on July 18, 1968, by Robert Noyce and Gordon Moore in Mountain View, California driving advancements in semiconductors and microprocessors that became the backbone of modern computing.\n",
        "The Rise of Technology Titans\n",
        "Samsung Electronics Co., Ltd., founded on January 13, 1969, by Lee Byung-chul in Su-dong, South Korea, initially focused on producing electrical appliances like televisions and refrigerators. As Samsung expanded into semiconductors, telecommunications, and digital media, it grew into a global technology leader. Similarly, Microsoft Corporation was founded on April 4, 1975, by Bill Gates and Paul Allen in Albuquerque, New Mexico, with the vision of placing a computer on every desk and in every home.\n",
        "In Cupertino, California, Apple Inc. was born on April 1, 1976, founded by Steve Jobs, Steve Wozniak, and Ronald Wayne. Their mission to make personal computing accessible and elegant revolutionized technology and design. A few years later, Oracle Corporation was established on June 16, 1977, by Larry Ellison, Bob Miner, and Ed Oates in Santa Clara, California. Specializing in relational databases, Oracle would become a cornerstone of enterprise software and cloud computing.\n",
        "NVIDIA Corporation, founded on April 5, 1993, by Jensen Huang, Chris Malachowsky, and Curtis Priem in Santa Clara, California, began with a focus on graphics processing units (GPUs) for gaming. Today, NVIDIA is a leader in artificial intelligence, deep learning, and autonomous systems, showcasing the power of continuous innovation.\n",
        "E-Commerce and the Internet Revolution\n",
        "The 1990s witnessed a dramatic shift toward e-commerce and internet technologies. Amazon.com Inc. was founded on July 5, 1994, by Jeff Bezos in a garage in Bellevue, Washington, with the vision of becoming the world's largest online bookstore. This vision rapidly expanded to encompass e-commerce, cloud computing, and digital streaming. Similarly, Google LLC was founded on September 4, 1998, by Larry Page and Sergey Brin, PhD students at Stanford University, in a garage in Menlo Park, California. Google's mission to \"organize the world's information\" transformed how we search, learn, and connect.\n",
        "In Asia, Alibaba Group Holding Limited was founded on June 28, 1999, by Jack Ma and 18 colleagues in Hangzhou, China. Originally an e-commerce platform connecting manufacturers with buyers, Alibaba expanded into cloud computing, digital entertainment, and financial technology, becoming a global powerhouse.\n",
        "In Europe, SAP SE was founded on April 1, 1972, by Dietmar Hopp, Hans-Werner Hector, Hasso Plattner, Klaus Tschira, and Claus Wellenreuther in Weinheim, Germany. Specializing in enterprise resource planning (ERP) software, SAP revolutionized how businesses manage operations and data.\n",
        "Social Media and Digital Platforms\n",
        "The 2000s brought a wave of social media and digital platforms that reshaped communication and commerce. LinkedIn Corporation was founded on December 28, 2002, by Reid Hoffman and a team from PayPal and Socialnet.com in Mountain View, California, focusing on professional networking. Facebook, Inc. (now Meta Platforms, Inc.) was launched on February 4, 2004, by Mark Zuckerberg and his college roommates in Cambridge, Massachusetts, evolving into a global social networking behemoth.\n",
        "Another transformative platform, Twitter, Inc., was founded on March 21, 2006, by Jack Dorsey, Biz Stone, and Evan Williams in San Francisco, California. Starting as a microblogging service, Twitter became a critical tool for communication and social commentary. Spotify AB, founded on April 23, 2006, by Daniel Ek and Martin Lorentzon in Stockholm, Sweden, leveraged streaming technology to democratize music consumption, fundamentally altering the music industry.\n",
        "In the realm of video-sharing, YouTube LLC was founded on February 14, 2005, by Steve Chen, Chad Hurley, and Jawed Karim in San Mateo, California. YouTube became the leading platform for user-generated video content, influencing global culture and media consumption.\n",
        "Innovators in Modern Technology\n",
        "Tesla, Inc., founded on July 1, 2003, by a group including Elon Musk, Martin Eberhard, Marc Tarpenning, JB Straubel, and Ian Wright, in San Carlos, California, championed the transition to sustainable energy with its electric vehicles and energy solutions. Airbnb, Inc., founded in August 2008 by Brian Chesky, Joe Gebbia, and Nathan Blecharczyk in San Francisco, California, disrupted traditional hospitality with its peer-to-peer lodging platform.\n",
        "In the realm of fintech, PayPal Holdings, Inc. was established in December 1998 by Peter Thiel, Max Levchin, Luke Nosek, and Ken Howery in Palo Alto, California. Originally a cryptography company, PayPal became a global leader in online payments. Stripe, Inc., founded in 2010 by Patrick and John Collison in Palo Alto, California, followed suit, simplifying online payments and enabling digital commerce.\n",
        "Square, Inc. (now Block, Inc.), founded on February 20, 2009, by Jack Dorsey and Jim McKelvey in San Francisco, California, revolutionized mobile payment systems with its simple and accessible card readers.\n",
        "Recent Disruptors\n",
        "Zoom Video Communications, Inc. was founded on April 21, 2011, by Eric Yuan in San Jose, California. Initially designed for video conferencing, Zoom became essential during the COVID-19 pandemic, transforming remote work and communication. Slack Technologies, LLC, founded in 2009 by Stewart Butterfield, Eric Costello, Cal Henderson, and Serguei Mourachov in Vancouver, Canada, redefined workplace communication with its innovative messaging platform.\n",
        "Rivian Automotive, Inc., founded on June 23, 2009, by RJ Scaringe in Plymouth, Michigan, entered the electric vehicle market with a focus on adventure and sustainability. SpaceX, established on March 14, 2002, by Elon Musk in Hawthorne, California, revolutionized aerospace with reusable rockets and ambitious plans for Mars exploration.\n",
        "TikTok, developed by ByteDance and launched in September 2016 by Zhang Yiming in Beijing, China, revolutionized short-form video content, becoming a cultural phenomenon worldwide.\n",
        "Conclusion\n",
        "These corporations, with their diverse beginnings and visionary founders, exemplify the interplay of innovation, timing, and strategic foresight that shapes industries and transforms markets. From repairing electronics in post-war Japan to building global e-commerce empires and redefining space exploration, their stories are milestones in the narrative of global economic transformation. Each reflects not only the aspirations of their founders but also the technological advancements and socio-economic trends of their time, serving as inspirations for future innovators.\n",
        "\"\"\"\n",
        "\n",
        "print(\"📄 Sample Essay Text Loaded\")\n",
        "print(f\"📊 Text Statistics:\")\n",
        "print(f\"  Length: {len(SAMPLE_ESSAY):,} characters\")\n",
        "print(f\"  Paragraphs: {len(split_into_paragraphs(SAMPLE_ESSAY))} paragraphs\")\n",
        "print(f\"  Words: {len(SAMPLE_ESSAY.split()):,} words\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f49a883",
      "metadata": {
        "id": "9f49a883"
      },
      "outputs": [],
      "source": [
        "# Configuration settings\n",
        "CONFIG = {\n",
        "    'delay_sec': 2.0,          # Delay between API calls (increase if hitting rate limits)\n",
        "    'max_paragraphs': None,    # Limit paragraphs for testing (None = process all)\n",
        "    'show_preview': True,      # Show preview of results\n",
        "    'output_csv': 'company_info.csv'  # Output CSV filename\n",
        "}\n",
        "\n",
        "print(\"⚙️ Configuration:\")\n",
        "for key, value in CONFIG.items():\n",
        "    print(f\"  {key}: {value}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"🚀 STARTING COMPANY EXTRACTION PROCESS\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c66e45d1",
      "metadata": {
        "id": "c66e45d1"
      },
      "outputs": [],
      "source": [
        "# Run the extraction process\n",
        "try:\n",
        "    # Extract companies from the essay\n",
        "    extracted_companies = run_extraction(\n",
        "        text=SAMPLE_ESSAY,\n",
        "        delay_sec=CONFIG['delay_sec'],\n",
        "        max_paragraphs=CONFIG['max_paragraphs']\n",
        "    )\n",
        "\n",
        "    print(f\"\\n✅ Extraction completed successfully!\")\n",
        "    print(f\"📊 Total companies extracted: {len(extracted_companies)}\")\n",
        "\n",
        "    # Show preview if enabled\n",
        "    if CONFIG['show_preview'] and extracted_companies:\n",
        "        print(f\"\\n\" + \"=\"*60)\n",
        "        preview_results(extracted_companies)\n",
        "        print(\"=\"*60)\n",
        "\n",
        "    # Write to CSV\n",
        "    if extracted_companies:\n",
        "        csv_result = write_csv(extracted_companies, CONFIG['output_csv'])\n",
        "        print(f\"\\n💾 {csv_result}\")\n",
        "\n",
        "        # Display CSV content\n",
        "        try:\n",
        "            with open(CONFIG['output_csv'], 'r', encoding='utf-8') as f:\n",
        "                csv_content = f.read()\n",
        "            print(f\"\\n📄 Generated CSV file content:\")\n",
        "            print(\"-\" * 40)\n",
        "            print(csv_content)\n",
        "            print(\"-\" * 40)\n",
        "        except Exception as e:\n",
        "            print(f\"Could not display CSV content: {e}\")\n",
        "\n",
        "    else:\n",
        "        print(\"⚠️ No companies were extracted from the text.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"❌ Extraction failed: {e}\")\n",
        "    print(\"Please check your API key and internet connection.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6123283",
      "metadata": {
        "id": "f6123283"
      },
      "outputs": [],
      "source": [
        "# Download the generated CSV file\n",
        "from google.colab import files\n",
        "\n",
        "# Check if CSV file exists and download it\n",
        "import os\n",
        "if os.path.exists(CONFIG['output_csv']):\n",
        "    print(f\"📥 Downloading {CONFIG['output_csv']}...\")\n",
        "    files.download(CONFIG['output_csv'])\n",
        "    print(\"✅ Download completed!\")\n",
        "else:\n",
        "    print(f\"❌ File {CONFIG['output_csv']} not found. Please run the extraction first.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
